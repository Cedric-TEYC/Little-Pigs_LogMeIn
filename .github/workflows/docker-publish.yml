name: Pipeline DevSecOps

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]
  schedule:
    - cron: '0 2 * * 1'
  workflow_dispatch:

permissions:
  contents: read
  security-events: write

jobs:
  mise_a_jour_backend:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: docker/setup-buildx-action@v3
      - run: docker build -t local-backend:latest ./backend

  controle_qualite:
    runs-on: ubuntu-latest
    needs: mise_a_jour_backend
    if: github.event_name != 'schedule'
    services:
      db:
        image: postgres:15
        env:
          POSTGRES_DB: logmeindb
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
        options: >-
          --health-cmd "pg_isready -U postgres"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 20
        ports:
          - 5432:5432
    env:
      DB_HOST: 127.0.0.1
      DB_PORT: 5432
      DB_NAME: logmeindb
      DB_USER: postgres
      DB_PASSWORD: postgres
    steps:
      - uses: actions/checkout@v4

      - name: Installer Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Installer d√©pendances Python
        run: |
          pip install --upgrade pip
          pip install -r backend/requirements.txt
          pip install pytest psycopg2-binary

      - name: Installer netcat (pour v√©rif du port)
        run: sudo apt-get update && sudo apt-get install -y netcat-openbsd

      - name: Attendre que le port 5432 du service db soit ouvert
        run: |
          for i in {1..20}; do
            nc -z 127.0.0.1 5432 && echo "Postgres up!" && exit 0
            sleep 1
          done
          echo "Postgres n‚Äôa pas r√©pondu sur le port 5432" && exit 1

      - name: G√©n√©rer le script d'init DB (YAML friendly)
        run: |
          echo "import psycopg2, os" > init_db.py
          echo "conn = psycopg2.connect(" >> init_db.py
          echo "    host=os.environ['DB_HOST']," >> init_db.py
          echo "    port=os.environ['DB_PORT']," >> init_db.py
          echo "    dbname=os.environ['DB_NAME']," >> init_db.py
          echo "    user=os.environ['DB_USER']," >> init_db.py
          echo "    password=os.environ['DB_PASSWORD']" >> init_db.py
          echo ")" >> init_db.py
          echo "cur = conn.cursor()" >> init_db.py
          echo "cur.execute('''" >> init_db.py
          echo "CREATE TABLE IF NOT EXISTS logs (" >> init_db.py
          echo "    id SERIAL PRIMARY KEY," >> init_db.py
          echo "    message TEXT NOT NULL," >> init_db.py
          echo "    level TEXT NOT NULL," >> init_db.py
          echo "    ip VARCHAR(45)," >> init_db.py
          echo "    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP" >> init_db.py
          echo ")''')" >> init_db.py
          echo "conn.commit()" >> init_db.py
          echo "cur.close()" >> init_db.py
          echo "conn.close()" >> init_db.py

      - name: Initialiser la base de donn√©es (table logs si besoin)
        run: python init_db.py

      - name: Lancer Pytest (log d√©taill√©)
        run: |
          export PYTHONPATH=backend
          pytest -v backend/tests

      - name: Tests pass√©s avec succ√®s 
        if: success()
        run: echo "‚úÖ Tous les tests Pytest sont pass√©s avec succ√®s !"

      - name: Analyse Bandit (Python)
        uses: tj-actions/bandit@v5
        continue-on-error: true
        with:
          targets: "./backend"

      - name: Linter Flake8
        uses: py-actions/flake8@v2
        continue-on-error: true
        with:
          path: "./backend"

      - name: Installer Trivy
        run: |
          sudo apt-get update && sudo apt-get install -y wget
          wget https://github.com/aquasecurity/trivy/releases/download/v0.50.2/trivy_0.50.2_Linux-64bit.deb
          sudo dpkg -i trivy_0.50.2_Linux-64bit.deb

      - name: Scan Trivy du code (SCA + vuln + secrets)
        run: trivy fs --exit-code 0 --severity CRITICAL,HIGH,MEDIUM --format table --scanners vuln,secret,config .

  construction_et_deploiement:
    runs-on: ubuntu-latest
    needs: controle_qualite
    if: github.event_name != 'schedule'
    env:
      DOCKERHUB_USERNAME: ${{ secrets.DOCKERHUB_USERNAME }}
      DOCKERHUB_TOKEN: ${{ secrets.DOCKERHUB_TOKEN }}
    steps:
      - uses: actions/checkout@v4
      - uses: docker/setup-buildx-action@v3
      - uses: docker/login-action@v3
        with:
          username: ${{ env.DOCKERHUB_USERNAME }}
          password: ${{ env.DOCKERHUB_TOKEN }}
      - name: Construire l‚Äôimage backend
        run: docker build -t $DOCKERHUB_USERNAME/littlepigs-backend:latest ./backend
      - name: Construire l‚Äôimage frontend
        run: docker build -t $DOCKERHUB_USERNAME/littlepigs-frontend:latest ./frontend
      - name: Construire l‚Äôimage nginx
        run: docker build -t $DOCKERHUB_USERNAME/littlepigs-nginx:latest -f nginx/Dockerfile .
      - name: Installer Trivy
        run: |
          sudo apt-get update && sudo apt-get install -y wget
          wget https://github.com/aquasecurity/trivy/releases/download/v0.50.2/trivy_0.50.2_Linux-64bit.deb
          sudo dpkg -i trivy_0.50.2_Linux-64bit.deb
      - name: Scanner l‚Äôimage backend avec Trivy
        run: trivy image --exit-code 0 --severity CRITICAL,HIGH,MEDIUM --format sarif -o trivy-backend.sarif $DOCKERHUB_USERNAME/littlepigs-backend:latest
      - name: Scanner l‚Äôimage frontend avec Trivy
        run: trivy image --exit-code 0 --severity CRITICAL,HIGH,MEDIUM --format sarif -o trivy-frontend.sarif $DOCKERHUB_USERNAME/littlepigs-frontend:latest
      - name: Scanner l‚Äôimage nginx avec Trivy
        run: trivy image --exit-code 0 --severity CRITICAL,HIGH,MEDIUM --format sarif -o trivy-nginx.sarif $DOCKERHUB_USERNAME/littlepigs-nginx:latest
      - name: Pousser l‚Äôimage backend
        run: docker push $DOCKERHUB_USERNAME/littlepigs-backend:latest
      - name: Pousser l‚Äôimage frontend
        run: docker push $DOCKERHUB_USERNAME/littlepigs-frontend:latest
      - name: Pousser l‚Äôimage nginx
        run: docker push $DOCKERHUB_USERNAME/littlepigs-nginx:latest
      - uses: github/codeql-action/upload-sarif@v3
        with:
          sarif_file: "trivy-backend.sarif"
          category: "trivy-backend"
      - uses: github/codeql-action/upload-sarif@v3
        with:
          sarif_file: "trivy-frontend.sarif"
          category: "trivy-frontend"
      - uses: github/codeql-action/upload-sarif@v3
        with:
          sarif_file: "trivy-nginx.sarif"
          category: "trivy-nginx"

  deploy_cluster:
    runs-on: self-hosted
    needs: construction_et_deploiement
    env:
      ADMIN_USER: ${{ secrets.ADMIN_USER }}
      ADMIN_IP: ${{ secrets.ADMIN_IP }}
      SSH_PRIVATE_KEY: ${{ secrets.SSH_PRIVATE_KEY }}
    steps:
      - uses: actions/checkout@v4
      - uses: webfactory/ssh-agent@v0.5.4
        with:
          ssh-private-key: ${{ env.SSH_PRIVATE_KEY }}
      - name: Copier scripts et configs sur admin
        run: |
          scp -o StrictHostKeyChecking=no cluster_config.yml $ADMIN_USER@$ADMIN_IP:~/
          scp -o StrictHostKeyChecking=no docker-compose.yml $ADMIN_USER@$ADMIN_IP:~/
          scp -o StrictHostKeyChecking=no scripts/deploy_cluster.sh $ADMIN_USER@$ADMIN_IP:~/
      - name: Installer yq sur admin
        run: |
          ssh -o StrictHostKeyChecking=no $ADMIN_USER@$ADMIN_IP "\
            if ! command -v yq &> /dev/null; then \
              wget -q https://github.com/mikefarah/yq/releases/latest/download/yq_linux_amd64 -O yq && \
              chmod +x yq && \
              sudo mv yq /usr/local/bin/yq; \
            fi \
          "
      - name: Lancer le script de d√©ploiement
        run: |
          ssh -o StrictHostKeyChecking=no $ADMIN_USER@$ADMIN_IP "chmod +x ~/deploy_cluster.sh && ~/deploy_cluster.sh"
      - name: V√©rifier acc√®s HTTP sur master et workers
        run: |
          MASTER_IP=$(ssh -o StrictHostKeyChecking=no $ADMIN_USER@$ADMIN_IP "yq e '.nodes.master.ip' cluster_config.yml")
          WORKERS_IPS=($(ssh -o StrictHostKeyChecking=no $ADMIN_USER@$ADMIN_IP "yq e '.nodes.workers[].ip' cluster_config.yml"))

          echo "üîç Test HTTP sur master..."
          curl -s -o /dev/null -w "%{http_code}\n" http://$MASTER_IP:3000 | grep -q "^200$" && echo "‚úÖ Master OK" || (echo "‚ùå Master KO" && exit 1)

          for IP in "${WORKERS_IPS[@]}"; do
            echo "üîç Test HTTP sur worker $IP..."
            curl -s -o /dev/null -w "%{http_code}\n" http://$IP:3000 | grep -q "^200$" && echo "‚úÖ Worker $IP OK" || (echo "‚ùå Worker $IP KO" && exit 1)
          done

  cluster_healthcheck:
    runs-on: self-hosted
    needs: deploy_cluster
    env:
      ADMIN_USER: ${{ secrets.ADMIN_USER }}
      ADMIN_IP: ${{ secrets.ADMIN_IP }}
      SSH_PRIVATE_KEY: ${{ secrets.SSH_PRIVATE_KEY }}
    steps:
      - uses: actions/checkout@v4
      - uses: webfactory/ssh-agent@v0.5.4
        with:
          ssh-private-key: ${{ secrets.SSH_PRIVATE_KEY }}
      - name: Copier healthcheck.sh et cluster_config.yml sur admin
        run: |
          scp -o StrictHostKeyChecking=no scripts/healthcheck.sh $ADMIN_USER@$ADMIN_IP:~/
          scp -o StrictHostKeyChecking=no cluster_config.yml $ADMIN_USER@$ADMIN_IP:~/
      - name: Ex√©cuter healthcheck (logs + v√©rifications)
        run: |
          ssh -o StrictHostKeyChecking=no $ADMIN_USER@$ADMIN_IP "chmod +x ~/healthcheck.sh && ~/healthcheck.sh"
      - name: R√©cup√©rer et afficher le log du healthcheck
        run: |
          scp -o StrictHostKeyChecking=no $ADMIN_USER@$ADMIN_IP:~/cluster_health.log ./cluster_health.log
          cat ./cluster_health.log
